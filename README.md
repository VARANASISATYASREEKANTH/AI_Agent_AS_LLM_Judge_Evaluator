# AI_Agent_AS_LLM_Judge_Evaluator(ðŸ›  In Progress: Will be updated soon)
Using AI Agent as LLM Judge Evaluator
<table border="1" cellpadding="8" cellspacing="0">
  <thead>
    <tr>
      <th>Evaluation Metric</th>
      <th>Methodology(LLM/AI Agent/ Multi-Agent)</th>
      <th>Strategy</th>
      <th>Remarks</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <td>Exact Match</td>
      <td>  ðŸ›  In Progress </td>
      <td>  ðŸ›  In Progress</td>
      <td> ðŸ›  In Progress </td>
    </tr>
    <tr>
      <td>BLEU(avg)</td>
      <td>ðŸ›  In Progress</td>
      <td>ðŸ›  In Progress</td>
      <td>ðŸ›  In Progress</td>
    </tr>
    <tr>
      <td>ROUGE L(avg)</td>
      <td>ðŸ›  In Progress</td>
      <td>ðŸ›  In Progress</td>
      <td>ðŸ›  In Progress</td>
    </tr>
    <tr>
      <td>Cosine similarity</td>
      <td>ðŸ›  In Progress</td>
      <td>ðŸ›  In Progress</td>
      <td>ðŸ›  In Progress</td>
    </tr>
    <tr>
      <td>BERT-f_1 score </td>
      <td>ðŸ›  In Progress </td>
      <td>ðŸ›  In Progress</td>
      <td>ðŸ›  In Progress</td>
    </tr>


    
  </tbody>
</table>
